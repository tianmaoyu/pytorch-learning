{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dbb59be",
   "metadata": {},
   "source": [
    "# U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tensorboard.summary.v1 import image\n",
    "from torch import Tensor, nn\n",
    "from torchvision import io\n",
    "import numpy as np\n",
    "from torchvision.transforms import functional\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a20f5b",
   "metadata": {},
   "source": [
    "## 一， utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9e56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def keep_image_size(path: str, size=(256, 256)) -> Image.Image:\n",
    "    img = Image.open(path)\n",
    "    max_size=max(img.size)\n",
    "    mask = Image.new('RGB', (max_size, max_size), (0, 0, 0))\n",
    "    mask.paste(img, (0, 0))\n",
    "    mask = mask.resize(size)\n",
    "    return mask\n",
    "\n",
    "def keep_mask_image_size(path: str, size=(256, 256)) -> Image.Image:\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    max_size=max(img.size)\n",
    "    mask = Image.new('L', (max_size, max_size), 0)\n",
    "    mask.paste(img, (0, 0))\n",
    "    mask = mask.resize(size)\n",
    "    return mask\n",
    "\n",
    "def pad_16(image: Tensor) -> Tensor:\n",
    "    width,height= functional.get_image_size(image)\n",
    "    pad_height = (16 - height % 16) % 16\n",
    "    pad_width = (16 - width % 16) % 16\n",
    "    # 表示在左、右,上、下、四个方向 mode：指定填充模式，可以是 “constant”、“reflect” 或 “replicate”；\n",
    "    pad_image = nn.functional.pad(image, (0, pad_width , 0, pad_height), mode='reflect')\n",
    "    return pad_image\n",
    "\n",
    "def show_image_memory_size(path: str):\n",
    "    img = io.read_image(path)\n",
    "    print(f\"img shape:{img.shape}\")\n",
    "    print(f\"data type:{img.dtype}\")\n",
    "\n",
    "    total_bytes = img.shape[0] * img.shape[1] * img.shape[2] * img.dtype.itemsize\n",
    "    print(f\"total bytes:{total_bytes},MB:{total_bytes/(1024*1024)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a737b",
   "metadata": {},
   "source": [
    "## 二， 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158ba5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "class DownSimple(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "class UpSimple(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        # 上采样 channel 减半\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        # 卷积 channel 减半\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, up_x, cat_left_x):\n",
    "        upx = self.up(up_x)\n",
    "        # 注意 链接时左右\n",
    "        x = torch.cat((cat_left_x, upx), dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = DoubleConv(in_channel, 64)\n",
    "\n",
    "        self.down1 = DownSimple(64, 128)\n",
    "        self.down2 = DownSimple(128, 256)\n",
    "        self.down3 = DownSimple(256, 512)\n",
    "        self.down4 = DownSimple(512, 1024)\n",
    "\n",
    "        self.up4 = UpSimple(1024,512)\n",
    "        self.up3 = UpSimple(512,256)\n",
    "        self.up2 = UpSimple(256,128)\n",
    "        self.up1 = UpSimple(128,64)\n",
    "\n",
    "        self.output = nn.Conv2d(64, out_channel, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.input(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        up4 = self.up4(x5,x4)\n",
    "        up3 = self.up3(up4,x3)\n",
    "        up2 = self.up2(up3,x2)\n",
    "        up1 = self.up1(up2,x1)\n",
    "        output= self.output(up1)\n",
    "\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4eadc3",
   "metadata": {},
   "source": [
    "## 三，dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46553b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from functorch.dim import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import shutil\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 路径，和最大 图片像素\n",
    "class WaterDataset(Dataset):\n",
    "    def __init__(self, path,max_size=2000_000):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.mask_path_list = []\n",
    "        self.image_path_list = []\n",
    "        self.max_size=max_size\n",
    "\n",
    "        self.mask_path = os.path.join(path, 'Annotations')\n",
    "        self.image_path = os.path.join(path, 'JPEGImages')\n",
    "\n",
    "        for dir_name, _, file_names in os.walk(self.mask_path):\n",
    "            for file_name in file_names:\n",
    "                mask_path = os.path.join(dir_name, file_name)\n",
    "                image_path_jpg = mask_path.replace(\"Annotations\", \"JPEGImages\").replace(\".png\", \".jpg\")\n",
    "                image_path_png = mask_path.replace(\"Annotations\", \"JPEGImages\")\n",
    "\n",
    "                if os.path.exists(image_path_jpg):\n",
    "                    self.image_path_list.append(image_path_jpg)\n",
    "                    self.mask_path_list.append(mask_path)\n",
    "                elif os.path.exists(image_path_png):\n",
    "                    self.image_path_list.append(image_path_png)\n",
    "                    self.mask_path_list.append(mask_path)\n",
    "                else:\n",
    "                    print(f\"找不到图片： {image_path_png}  ｛image_path_jpg｝\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_path_list)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[Tensor, Tensor]:\n",
    "        image_path = self.image_path_list[index]\n",
    "        image_mask_path = self.mask_path_list[index]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            mask_image = Image.open(image_mask_path).convert(\"L\")\n",
    "\n",
    "            # 图片太大，进行等比列缩放-内存不足\n",
    "\n",
    "            width, height = image.size\n",
    "            pixel_num = width * height\n",
    "            if pixel_num > self.max_size:\n",
    "                scale_factor = self.max_size / pixel_num\n",
    "                new_width = int(width * scale_factor)\n",
    "                new_height = int(height * scale_factor)\n",
    "                # 缩放图像,建议双线性插值\n",
    "                image = image.resize((new_width, new_height), resample=Image.LANCZOS)\n",
    "                mask_image = mask_image.resize((new_width, new_height), resample=Image.LANCZOS)\n",
    "\n",
    "            image = transform(image)\n",
    "            mask_image = transform(mask_image)\n",
    "\n",
    "            return pad_16(image), pad_16(mask_image)\n",
    "        except Exception as e:\n",
    "            print(f\"数据错误: {image_path}\", e)\n",
    "            return torch.randn(0, 1, 1, 1), torch.randn(0, 1, 1, 1)\n",
    "\n",
    "\n",
    "transform512 = transforms.Compose([\n",
    "    transforms.Resize(512),  # 保持长宽比，调整最短边为512像素\n",
    "    transforms.CenterCrop(512),  # 从中心裁剪512x512的图片\n",
    "    transforms.ToTensor()  # 转换成Tensor，方便后续处理\n",
    "])\n",
    "\n",
    "\n",
    "class WaterDataset512(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.mask_path_list = []\n",
    "        self.image_path_list = []\n",
    "\n",
    "        self.mask_path = os.path.join(path, 'Annotations')\n",
    "        self.image_path = os.path.join(path, 'JPEGImages')\n",
    "\n",
    "        for dir_name, _, file_names in os.walk(self.mask_path):\n",
    "            for file_name in file_names:\n",
    "                mask_path = os.path.join(dir_name, file_name)\n",
    "                image_path_jpg = mask_path.replace(\"Annotations\", \"JPEGImages\").replace(\".png\", \".jpg\")\n",
    "                image_path_png = mask_path.replace(\"Annotations\", \"JPEGImages\")\n",
    "\n",
    "                if os.path.exists(image_path_jpg):\n",
    "                    self.image_path_list.append(image_path_jpg)\n",
    "                    self.mask_path_list.append(mask_path)\n",
    "                elif os.path.exists(image_path_png):\n",
    "                    self.image_path_list.append(image_path_png)\n",
    "                    self.mask_path_list.append(mask_path)\n",
    "                else:\n",
    "                    print(f\"找不到图片： {image_path_png}  ｛image_path_jpg｝\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_path_list)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[Tensor, Tensor]:\n",
    "        image_path = self.image_path_list[index]\n",
    "        image_mask_path = self.mask_path_list[index]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            mask_image = Image.open(image_mask_path).convert(\"L\")\n",
    "\n",
    "            image = transform512(image)\n",
    "            mask_image = transform512(mask_image)\n",
    "\n",
    "            return image, mask_image\n",
    "        except  Exception as e:\n",
    "            print(f\"数据错误: {image_path},{e}\")\n",
    "            return torch.randn(0, 1, 1, 1), torch.randn(0, 1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21595c6",
   "metadata": {},
   "source": [
    "## 四，训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74516a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找不到图片： E:\\语义分割\\water_v2\\water_v2\\JPEGImages\\stream2\\12_00.json  ｛image_path_jpg｝\n",
      "找不到图片： E:\\语义分割\\water_v2\\water_v2\\JPEGImages\\stream2\\12_00_json\\img.png  ｛image_path_jpg｝\n",
      "找不到图片： E:\\语义分割\\water_v2\\water_v2\\JPEGImages\\stream2\\12_00_json\\info.yaml  ｛image_path_jpg｝\n",
      "找不到图片： E:\\语义分割\\water_v2\\water_v2\\JPEGImages\\stream2\\12_00_json\\label.png  ｛image_path_jpg｝\n",
      "找不到图片： E:\\语义分割\\water_v2\\water_v2\\JPEGImages\\stream2\\12_00_json\\label_names.txt  ｛image_path_jpg｝\n",
      "找不到图片： E:\\语义分割\\water_v2\\water_v2\\JPEGImages\\stream2\\12_00_json\\label_viz.png  ｛image_path_jpg｝\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 11:39:42,496 - train - INFO - epoch:0 step: 0,loss: 0.7216627597808838 iou:3.349415026605129e-05\n",
      "2024-09-13 11:39:42,496 - train - INFO - epoch:0 step: 0,loss: 0.7216627597808838 iou:3.349415026605129e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 106\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m model_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m loss_result \u001b[38;5;241m=\u001b[39m loss(model_result, mask_images)\n\u001b[0;32m    110\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 66\u001b[0m, in \u001b[0;36mUnet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     64\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput(x)\n\u001b[0;32m     65\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x1)\n\u001b[1;32m---> 66\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown3(x3)\n\u001b[0;32m     68\u001b[0m x5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown4(x4)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 27\u001b[0m, in \u001b[0;36mDownSimple.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import *\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import functional, transforms\n",
    "import logging\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "\n",
    "\n",
    "\n",
    "# 训练停止条件，连续 多少次没有增长\n",
    "class TrainStop:\n",
    "    def __init__(self, count=3):\n",
    "        self.count = count\n",
    "        self.score_list = [0.0]\n",
    "        self.best = 0.0\n",
    "        self.trigger_count = 0\n",
    "\n",
    "    def __call__(self, score: float) -> bool:\n",
    "        self.score_list.append(score)\n",
    "        total = sum(self.score_list[-self.count:])\n",
    "        # 最佳分数： 最后几次平均分\n",
    "        mean=total / self.count\n",
    "        if  mean > self.best:\n",
    "            self.best = mean\n",
    "\n",
    "        # 分数没有超过之前，已经 count 次，就停止\n",
    "        if self.best > score:\n",
    "            self.trigger_count += 1\n",
    "            if self.trigger_count > self.count+1:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "# 日志\n",
    "def config_logger(name=\"train\"):\n",
    "    # 设置日志的基本配置\n",
    "    logger = logging.getLogger(\"train\")\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    # 创建一个handler，用于写入日志文件\n",
    "    file_handler = logging.FileHandler('app.log')\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    # 再创建一个handler，用于输出到控制台\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(logging.DEBUG)\n",
    "    # 定义handler的输出格式\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    # 给logger添加handler\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(stream_handler)\n",
    "    return logger\n",
    "\n",
    "\n",
    "# 合并 两个datasets\n",
    "def merge_datasets(dataset_1, dataset_2):\n",
    "    # 合并两个数据集的图像和掩码路径列表\n",
    "    merged_image_paths = dataset_1.image_path_list + dataset_2.image_path_list\n",
    "    merged_mask_paths = dataset_1.mask_path_list + dataset_2.mask_path_list\n",
    "\n",
    "    # 使用合并后的路径列表创建一个新的数据集实例\n",
    "    new_dataset = WaterDataset(dataset_1.path)\n",
    "    new_dataset.image_path_list = merged_image_paths\n",
    "    new_dataset.mask_path_list = merged_mask_paths\n",
    "\n",
    "    return new_dataset\n",
    "\n",
    "logger = config_logger()\n",
    "train_stop = TrainStop(count=3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset1 = WaterDataset(f\"E:\\语义分割\\water_v1\\water_v1\")\n",
    "dataset2 = WaterDataset(f\"E:\\语义分割\\water_v2\\water_v2\")\n",
    "dataset = merge_datasets(dataset1, dataset2)\n",
    "\n",
    "# 把数据拆分为 9：1 \n",
    "total_length = len(dataset)\n",
    "var_length = int(total_length * 0.1)\n",
    "train_dataset, val_dataset = random_split(dataset, [total_length - var_length, var_length])\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=1)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=1)\n",
    "\n",
    "\n",
    "model = Unet(3, 1).to(device)\n",
    "loss = nn.BCELoss().to(device)\n",
    "optimizer = Adam(model.parameters(), 0.001)\n",
    "mean_iou = MeanIoU(num_classes=2).to(device)\n",
    "\n",
    "for epoch in range(20):\n",
    "    # 训练\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    mean_iou.reset()\n",
    "    \n",
    "    for step, (images, mask_images) in enumerate(train_dataloader):\n",
    "        # todo 返回 None,或者 这句话写到下面 -会还是对图片进行 采集，会出现一个问题\n",
    "        images, mask_images = images.to(device), mask_images.to(device)\n",
    "        height, width = functional.get_image_size(images)\n",
    "\n",
    "        if images.shape[1] > 3:\n",
    "            continue\n",
    "        if mask_images.shape[1] > 1:\n",
    "            continue\n",
    "        if images.shape[2] == 1:\n",
    "            continue\n",
    "\n",
    "        model_result = model(images)\n",
    "\n",
    "        loss_result = loss(model_result, mask_images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_result.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 指标\n",
    "        total_loss += loss_result.item()\n",
    "        mean_iou.update((model_result > 0.5).long(), mask_images.long())\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            logger.info(f\"epoch:{epoch} step: {step},loss: {loss_result.item()} iou:{mean_iou.compute().item() / 50}\")\n",
    "            mean_iou.reset()\n",
    "\n",
    "    # 验证\n",
    "    model.eval()\n",
    "    var_mean_iou = 0\n",
    "    mean_iou.reset()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_dataloader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            # 阈值化并转换为整数类型\n",
    "            outputs = (outputs > 0.5).long()\n",
    "            # 更新 MeanIoU- 内部是累加\n",
    "            mean_iou.update(outputs, targets.long())\n",
    "\n",
    "        logger.info(\"---\" * 20)\n",
    "        var_mean_iou = mean_iou.compute().item() / len(val_dataloader)\n",
    "        logger.info(f\"第epoch: {epoch}  Var Mean IoU: {var_mean_iou} total_loss :{total_loss}\")\n",
    "       \n",
    "  \n",
    "    # 保存模型\n",
    "    torch.save(model, f\"unet-{epoch}.pth\")\n",
    "    logger.info(f\"模型已经保存：unet-{epoch}.pth\")\n",
    "\n",
    "    # 是否停止\n",
    "    is_stop = train_stop(var_mean_iou)\n",
    "    if is_stop:\n",
    "        logger.info(f\"停止训练: epoch:{epoch} 最佳iou {train_stop.best} , score_list:{train_stop.score_list}\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
